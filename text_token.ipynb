{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.read_excel('CXIRG_Data\\\\train_data\\\\reports.xlsx', engine='openpyxl')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = '[CLS] ' + text\n",
    "    text = re.sub('_x000D_', ' ', text)\n",
    "    text = re.sub('[0-9]\\)|>|-|[0-9]\\.|', '', text)\n",
    "    # print(text)\n",
    "    gptpat = re.compile(r\"\"\"\\[[C][L][S]]|\\n|[:.,]| [L]4+| *3+[rd]+| *4+[th]+| [LR]\\'t|[LR]\\'t| T[0-9]+|T[0-9]+| [a-zA-Z]/[a-zA-Z]|[a-zA-Z]/[a-zA-Z]| ?\\p{L}+| ?\\p{N}+\"\"\")\n",
    "    text = re.findall(gptpat, text)\n",
    "    tokens = []\n",
    "    for token in text:\n",
    "        if len(token) > 0:\n",
    "            tokens.append(token)\n",
    "    \n",
    "    def check_token_head(tokens):\n",
    "        while tokens[0] == ' ':\n",
    "            tokens = tokens[1:]\n",
    "            \n",
    "        return tokens\n",
    "    \n",
    "    tokens = check_token_head(tokens)\n",
    "    \n",
    "    # print(len(tokens))\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "report_texts = report['text'].apply(preprocess_text)\n",
    "# report_texts[17]\n",
    "len(report_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411,\n",
       " {'\\n': 728,\n",
       "  '.': 612,\n",
       "  ':': 146,\n",
       "  ' lung': 101,\n",
       "  ' of': 92,\n",
       "  '[CLS]': 89,\n",
       "  ' Chest': 75,\n",
       "  ' and': 65,\n",
       "  ' aorta': 63,\n",
       "  'Impression': 58,\n",
       "  ' right': 58,\n",
       "  ' spine': 57,\n",
       "  ' heart': 57,\n",
       "  ' bilateral': 52,\n",
       "  ' view': 49,\n",
       "  ' in': 49,\n",
       "  ' size': 48,\n",
       "  ' left': 47,\n",
       "  'S/P': 47,\n",
       "  ' film': 43,\n",
       "  ' shows': 43,\n",
       "  ' pleural': 42,\n",
       "  ' tube': 40,\n",
       "  ' plain': 37,\n",
       "  'Normal': 37,\n",
       "  ' upper': 34,\n",
       "  ' with': 33,\n",
       "  ' showed': 32,\n",
       "  ' insertion': 31,\n",
       "  'Increased': 30,\n",
       "  ' lower': 29,\n",
       "  ' CP': 29,\n",
       "  ' both': 28,\n",
       "  ' S/P': 28,\n",
       "  ' lungs': 24,\n",
       "  ' NG': 24,\n",
       "  ' infiltrations': 23,\n",
       "  ' effusion': 22,\n",
       "  'No': 22,\n",
       "  ' AP': 21,\n",
       "  ' PA': 21,\n",
       "  'Blunting': 21,\n",
       "  'DJD': 21,\n",
       "  ' angles': 21,\n",
       "  ' Rt': 20,\n",
       "  ' endotracheal': 19,\n",
       "  ' jugular': 19,\n",
       "  'Bilateral': 19,\n",
       "  ' mediastinum': 19,\n",
       "  ',': 19,\n",
       "  'Atherosclerotic': 18,\n",
       "  'Suspect': 18,\n",
       "  \" L't\": 18,\n",
       "  ' patch': 18,\n",
       "  ' tortuous': 17,\n",
       "  \" R't\": 17,\n",
       "  ' atherosclerotic': 17,\n",
       "  ' apical': 16,\n",
       "  ' thickening': 16,\n",
       "  ' DJD': 16,\n",
       "  ' subclavian': 16,\n",
       "  ' is': 16,\n",
       "  ' mass': 15,\n",
       "  ' chest': 15,\n",
       "  ' osteoporosis': 15,\n",
       "  'The': 15,\n",
       "  ' markings': 14,\n",
       "  ' CVC': 14,\n",
       "  ' angle': 14,\n",
       "  ' widening': 14,\n",
       "  ' shadow': 14,\n",
       "  'Spondylosis': 13,\n",
       "  ' pulmonary': 13,\n",
       "  'Chest': 13,\n",
       "  'Suspicious': 13,\n",
       "  ' at': 12,\n",
       "  ' Bilateral': 12,\n",
       "  's/p': 12,\n",
       "  'Tortuous': 12,\n",
       "  ' dilated': 12,\n",
       "  ' hemidiaphragm': 11,\n",
       "  ' abdomen': 11,\n",
       "  ' s/p': 11,\n",
       "  ' nodules': 11,\n",
       "  ' not': 11,\n",
       "  'Scoliosis': 11,\n",
       "  'Cardiomegaly': 10,\n",
       "  ' fracture': 10,\n",
       "  ' be': 10,\n",
       "  ' R/O': 10,\n",
       "  ' Lt': 10,\n",
       "  ' infiltrates': 10,\n",
       "  ' ribs': 9,\n",
       "  ' cannot': 9,\n",
       "  ' middle': 9,\n",
       "  ' on': 9,\n",
       "  ' fixation': 9,\n",
       "  ' edema': 9,\n",
       "  ' Suspect': 8,\n",
       "  ' consolidation': 8,\n",
       "  'Atherosclerosis': 8,\n",
       "  ' patches': 8,\n",
       "  ' intubation': 8,\n",
       "  ' enlargement': 8,\n",
       "  ' Blunting': 8,\n",
       "  ' excluded': 8,\n",
       "  'Enlarged': 7,\n",
       "  ' Superimposed': 7,\n",
       "  ' the': 7,\n",
       "  ' pigtail': 7,\n",
       "  ' Normal': 7,\n",
       "  ' CVP': 7,\n",
       "  ' hilar': 7,\n",
       "  ' nodule': 7,\n",
       "  ' widened': 7,\n",
       "  ' PortAcath': 7,\n",
       "  ' pneumonia': 7,\n",
       "  ' atelectasis': 6,\n",
       "  'Mild': 6,\n",
       "  ' costophrenic': 6,\n",
       "  ' reticulonodular': 6,\n",
       "  ' obvious': 6,\n",
       "  'Right': 6,\n",
       "  ' enlarged': 6,\n",
       "  ' pneumothorax': 6,\n",
       "  ' lesion': 5,\n",
       "  ' field': 5,\n",
       "  ' infiltration': 5,\n",
       "  'Left': 5,\n",
       "  'Elevated': 5,\n",
       "  ' Spondylosis': 5,\n",
       "  ' scoliosis': 5,\n",
       "  ' cardiac': 5,\n",
       "  ' implantation': 5,\n",
       "  ' clips': 5,\n",
       "  ' X': 5,\n",
       "  ' ray': 5,\n",
       "  ' Atherosclerosis': 5,\n",
       "  ' drainage': 5,\n",
       "  ' No': 5,\n",
       "  ' nor': 5,\n",
       "  ' aortic': 5,\n",
       "  ' small': 5,\n",
       "  ' fibrosis': 5,\n",
       "  'Compatible': 5,\n",
       "  ' emphysema': 5,\n",
       "  ' hernia': 5,\n",
       "  ' thoracolumbar': 4,\n",
       "  ' Atherosclerotic': 4,\n",
       "  ' operation': 4,\n",
       "  ' sternotomy': 4,\n",
       "  ' calcified': 4,\n",
       "  ' A': 4,\n",
       "  ' View': 4,\n",
       "  ' Suspicious': 4,\n",
       "  ' Scoliosis': 4,\n",
       "  ' Mild': 4,\n",
       "  ' Susp': 4,\n",
       "  'Subcutaneous': 4,\n",
       "  ' for': 4,\n",
       "  'Fibrotic': 3,\n",
       "  'Old': 3,\n",
       "  ' stent': 3,\n",
       "  ' Increased': 3,\n",
       "  ' cardiomegaly': 3,\n",
       "  ' portA': 3,\n",
       "  ' density': 3,\n",
       "  'Diffuse': 3,\n",
       "  ' Obscured': 3,\n",
       "  ' Status': 3,\n",
       "  ' post': 3,\n",
       "  ' intrapleural': 3,\n",
       "  'IMP': 3,\n",
       "  ' One': 3,\n",
       "  ' arch': 3,\n",
       "  ' metastasis': 3,\n",
       "  ' medial': 3,\n",
       "  ' Lspine': 3,\n",
       "  ' TB': 3,\n",
       "  ' TL': 3,\n",
       "  ' tracheostomy': 3,\n",
       "  \"R't\": 3,\n",
       "  ' increased': 3,\n",
       "  ' wall': 3,\n",
       "  ' repair': 3,\n",
       "  ' diaphragmatic': 3,\n",
       "  'Calcified': 3,\n",
       "  ' Compression': 2,\n",
       "  ' biliary': 2,\n",
       "  ' fields': 2,\n",
       "  ' Cardiomegaly': 2,\n",
       "  'Borderline': 2,\n",
       "  ' suspected': 2,\n",
       "  ' pacemaker': 2,\n",
       "  'Surgical': 2,\n",
       "  'Consolidation': 2,\n",
       "  ' vein': 2,\n",
       "  ' silhouette': 2,\n",
       "  ' bone': 2,\n",
       "  ' T11': 2,\n",
       "  ' illdefined': 2,\n",
       "  ' out': 2,\n",
       "  ' Elevation': 2,\n",
       "  ' Enlarged': 2,\n",
       "  ' Osteophytes': 2,\n",
       "  ' change': 2,\n",
       "  ' faint': 2,\n",
       "  ' Left': 2,\n",
       "  ' Old': 2,\n",
       "  ' SVC': 2,\n",
       "  ' Tortuous': 2,\n",
       "  ' Clips': 2,\n",
       "  ' Pulmonary': 2,\n",
       "  'R/O': 2,\n",
       "  ' coronary': 2,\n",
       "  ' stenting': 2,\n",
       "  ' Elevated': 2,\n",
       "  ' atrium': 2,\n",
       "  ' valve': 2,\n",
       "  ' paratracheal': 2,\n",
       "  ' or': 2,\n",
       "  ' brachiocephalic': 2,\n",
       "  ' artery': 2,\n",
       "  ' tubes': 2,\n",
       "  ' old': 2,\n",
       "  ' multiple': 2,\n",
       "  ' bony': 2,\n",
       "  ' metastases': 2,\n",
       "  ' centrilobular': 2,\n",
       "  'Pulmonary': 2,\n",
       "  ' completely': 2,\n",
       "  ' Cspine': 2,\n",
       "  'Sutures': 2,\n",
       "  ' neck': 2,\n",
       "  ' walls': 2,\n",
       "  ' OG': 2,\n",
       "  ' hiatal': 2,\n",
       "  ' wire': 2,\n",
       "  'Compression': 2,\n",
       "  ' Permcath': 2,\n",
       "  'Susp': 2,\n",
       "  ' placement': 2,\n",
       "  'A': 2,\n",
       "  ' basal': 2,\n",
       "  ' lesions': 2,\n",
       "  ' Fracture': 2,\n",
       "  ' L': 1,\n",
       "  ' fractures': 1,\n",
       "  'Clips': 1,\n",
       "  ' thoracic': 1,\n",
       "  ' associated': 1,\n",
       "  ' focal': 1,\n",
       "  ' LUQ': 1,\n",
       "  'Recommend': 1,\n",
       "  ' clinical': 1,\n",
       "  ' correlation': 1,\n",
       "  'Pneumoperitoneum': 1,\n",
       "  ' congestion': 1,\n",
       "  ' via': 1,\n",
       "  'Mass': 1,\n",
       "  'Heterogeneous': 1,\n",
       "  ' partial': 1,\n",
       "  ' collapse': 1,\n",
       "  ' T9': 1,\n",
       "  ' vertebrae': 1,\n",
       "  ' patchy': 1,\n",
       "  ' opacities': 1,\n",
       "  'Presence': 1,\n",
       "  ' Patchy': 1,\n",
       "  ' opacified': 1,\n",
       "  ' eft': 1,\n",
       "  ' infectious': 1,\n",
       "  ' processes': 1,\n",
       "  ' ruled': 1,\n",
       "  ' Engorgement': 1,\n",
       "  ' hilae': 1,\n",
       "  ' calcifications': 1,\n",
       "  ' deformans': 1,\n",
       "  ' drainge': 1,\n",
       "  ' thorax': 1,\n",
       "  ' conduction': 1,\n",
       "  ' devices': 1,\n",
       "  ' nasogastric': 1,\n",
       "  ' Focal': 1,\n",
       "  ' groundglass': 1,\n",
       "  ' opacity': 1,\n",
       "  ' Sclerotic': 1,\n",
       "  ' L4': 1,\n",
       "  ' favor': 1,\n",
       "  ' Surgical': 1,\n",
       "  ' retrocardiac': 1,\n",
       "  ' pleura': 1,\n",
       "  ' Faint': 1,\n",
       "  ' fibrotic': 1,\n",
       "  ' nodular': 1,\n",
       "  ' lateral': 1,\n",
       "  ' mediastinal': 1,\n",
       "  ' Both': 1,\n",
       "  ' are': 1,\n",
       "  ' sharp': 1,\n",
       "  ' 3rd': 1,\n",
       "  ' 4th': 1,\n",
       "  'Large': 1,\n",
       "  ' occupying': 1,\n",
       "  ' Surgery': 1,\n",
       "  ' postradiotherapy': 1,\n",
       "  ' elevation': 1,\n",
       "  ' Interstitial': 1,\n",
       "  ' port': 1,\n",
       "  ' level': 1,\n",
       "  ' Postinflammatory': 1,\n",
       "  ' abdominal': 1,\n",
       "  ' retained': 1,\n",
       "  ' Reticular': 1,\n",
       "  ' emphysematous': 1,\n",
       "  ' Right': 1,\n",
       "  ' Borderline': 1,\n",
       "  ' Compatible': 1,\n",
       "  'Elevation': 1,\n",
       "  'Dilated': 1,\n",
       "  ' MRM': 1,\n",
       "  ' mitral': 1,\n",
       "  ' disease': 1,\n",
       "  ' arterial': 1,\n",
       "  'Increase': 1,\n",
       "  ' active': 1,\n",
       "  ' engorged': 1,\n",
       "  ' Plain': 1,\n",
       "  ' Film': 1,\n",
       "  'pneumonia': 1,\n",
       "  ' ankylosing': 1,\n",
       "  ' spondylitis': 1,\n",
       "  ' cervicothoracic': 1,\n",
       "  ' internal': 1,\n",
       "  ' fixations': 1,\n",
       "  ' Infiltration': 1,\n",
       "  ' airspace': 1,\n",
       "  ' superimposed': 1,\n",
       "  ' Mediastinum': 1,\n",
       "  'Generalized': 1,\n",
       "  ' LUL': 1,\n",
       "  ' lobectomy': 1,\n",
       "  ' RUL': 1,\n",
       "  ' RML': 1,\n",
       "  ' wedge': 1,\n",
       "  ' resection': 1,\n",
       "  ' effusions': 1,\n",
       "  ' white': 1,\n",
       "  ' linear': 1,\n",
       "  ' bluntening': 1,\n",
       "  ' subcutaneous': 1,\n",
       "  ' Spur': 1,\n",
       "  ' arm': 1,\n",
       "  ' PICC': 1,\n",
       "  ' clavicle': 1,\n",
       "  'T1': 1,\n",
       "  ' Surgcial': 1,\n",
       "  ' Calcified': 1,\n",
       "  ' congenial': 1,\n",
       "  'Bulging': 1,\n",
       "  ' area': 1,\n",
       "  ' probably': 1,\n",
       "  ' due': 1,\n",
       "  ' to': 1,\n",
       "  ' thymus': 1,\n",
       "  'Coarsening': 1,\n",
       "  ' peribronchovascular': 1,\n",
       "  ' bundles': 1,\n",
       "  'favoring': 1,\n",
       "  ' inflammatory': 1,\n",
       "  ' process': 1,\n",
       "  ' metallic': 1,\n",
       "  ' subsegmental': 1,\n",
       "  ' replacement': 1,\n",
       "  ' SwanGanz': 1,\n",
       "  ' catheterization': 1,\n",
       "  \"L't\": 1,\n",
       "  ' hydropneumothorax': 1,\n",
       "  ' inadequate': 1,\n",
       "  ' position': 1,\n",
       "  'Stent': 1,\n",
       "  ' axillary': 1,\n",
       "  ' region': 1,\n",
       "  ' consider': 1,\n",
       "  ' renal': 1,\n",
       "  ' stones': 1,\n",
       "  'Radiopaque': 1,\n",
       "  ' hypertension': 1,\n",
       "  ' Subsegmental': 1,\n",
       "  ' Xray': 1,\n",
       "  ' But': 1,\n",
       "  ' if': 1,\n",
       "  ' there': 1,\n",
       "  ' still': 1,\n",
       "  ' clinically': 1,\n",
       "  ' strong': 1,\n",
       "  ' suspicion': 1,\n",
       "  ' CT': 1,\n",
       "  ' may': 1,\n",
       "  ' arranged': 1,\n",
       "  ' further': 1,\n",
       "  ' evaluation': 1,\n",
       "  ' Fibronodular': 1,\n",
       "  ' Blunted': 1,\n",
       "  'S': 1,\n",
       "  'P': 1,\n",
       "  ' show': 1,\n",
       "  ' rightsided': 1,\n",
       "  ' aberrant': 1,\n",
       "  ' Kommerell': 1,\n",
       "  ' diverticulum': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_dict(df):\n",
    "    vocab_dict = {}\n",
    "    for row in df:\n",
    "        for token in row:\n",
    "            vocab_dict[token] = vocab_dict.get(token, 0) + 1\n",
    "    return vocab_dict\n",
    "\n",
    "vocab_dict = create_dict(report_texts)\n",
    "sorted_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "len(sorted_dict) ,sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word piece tokenize\n",
    "def build_vocab(word_dict):\n",
    "    itos = {}\n",
    "    stoi = {}\n",
    "    for i, token in enumerate(word_dict.items()):\n",
    "        stoi[token[0]] = i\n",
    "        itos[i] = token[0]\n",
    "    return itos, stoi\n",
    "\n",
    "itos, stoi = build_vocab(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda l : ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]\\nChest plain film shows:\\nImpression:\\nCompatible with rightsided aortic arch with aberrant left subclavian artery and Kommerell diverticulum.\\nSuspect bilateral lower lung patches.\\nIncreased infiltrations in both lungs.\\nBlunting bilateral CP angles.\\nTortuous atherosclerotic dilated aorta.\\nCardiomegaly.\\nScoliosis, DJD and osteoporosis of spine.\\n Fracture of right ribs.\\nS/P Rt subclavian CVC insertion.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''\n",
    "Chest plain film shows:\n",
    "Impression:\n",
    "-Compatible with right-sided aortic arch with aberrant left subclavian artery and Kommerell diverticulum.\n",
    "-Suspect bilateral lower lung patches. \n",
    "-Increased infiltrations in both lungs.\n",
    "-Blunting bilateral CP angles.\n",
    "-Tortuous atherosclerotic dilated aorta.\n",
    "-Cardiomegaly.\n",
    "-Scoliosis, DJD and osteoporosis of spine.\n",
    " Fracture of right ribs. \n",
    "S/P Rt subclavian CVC insertion. \n",
    "'''\n",
    "\n",
    "# encode(preprocess_text(text))\n",
    "decode(encode(preprocess_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer():\n",
    "    \n",
    "    def __init__(self, word_dict):\n",
    "        self.word_dict = word_dict\n",
    "        \n",
    "        def build_vocab(word_dict):\n",
    "            itos = {}\n",
    "            stoi = {}\n",
    "            for i, token in enumerate(word_dict.items()):\n",
    "                stoi[token[0]] = i\n",
    "                itos[i] = token[0]\n",
    "            return itos, stoi\n",
    "        \n",
    "        self.itos, self.stoi = build_vocab(self.word_dict)\n",
    "        self.encode_ = lambda s : [stoi[c] for c in s]\n",
    "        self.decode_ = lambda l : ''.join([itos[i] for i in l])\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.encode_(text)\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        return self.decode_(tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import math\n",
    "\n",
    "class CustomReportDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, text_df, split='train', word_dict=None):\n",
    "        assert split in ['train', 'valid', 'test']\n",
    "        n_samples = {\n",
    "            'train' : len(text_df) * 0.9,\n",
    "            'valid' : len(text_df) * 0.1,\n",
    "            'test' : len(text_df),\n",
    "        }[split]\n",
    "        if type(text_df) is not list:\n",
    "            text_df = list(text_df)\n",
    "        self.df = random.sample(text_df, int(n_samples))\n",
    "        self.tokenizer = CustomTokenizer(word_dict)\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        target = self.df[index]\n",
    "        target = torch.tensor(self.tokenizer.encode(target))\n",
    "        return target\n",
    "        \n",
    "    # def decode(self, tokens):\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tokenizer(sorted_dict)\n",
    "train_df = CustomReportDataset(report_texts, split='train', word_dict=sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomBlockSeq2Batch(df, block_size, batch_size, threshold=50, device=None, target_idx=None):\n",
    "    \n",
    "    # get rid of the sequence that len < threshold\n",
    "    # n_df = []\n",
    "    # for idx, data in enumerate(df):\n",
    "    #     if len(data) >= threshold: n_df.append(data)\n",
    "    \n",
    "    # get random batch\n",
    "    if target_idx == None: target_idx = random.randint(0, len(df) - 1)\n",
    "    ix = torch.randint(len(df[target_idx]) - block_size, (batch_size, ))\n",
    "    ix[0] = 0                                 # test for make sure CLS\n",
    "    x = torch.stack([df[target_idx][i:i+block_size] for i in ix])\n",
    "    y = torch.stack([df[target_idx][i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = CustomBlockSeq2Batch(train_df, block_size, batch_size, device='cpu')\n",
    "# x, y, x.shape, y.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [CLS] the target : 0\n",
      "when input is [CLS]\n",
      " the target : 73\n",
      "when input is [CLS]\n",
      "Chest the target : 23\n",
      "when input is [CLS]\n",
      "Chest plain the target : 19\n",
      "when input is [CLS]\n",
      "Chest plain film the target : 14\n",
      "when input is [CLS]\n",
      "Chest plain film view the target : 27\n",
      "when input is [CLS]\n",
      "Chest plain film view showed the target : 2\n",
      "when input is [CLS]\n",
      "Chest plain film view showed: the target : 0\n",
      "when input is Chest the target : 23\n",
      "when input is Chest plain the target : 19\n",
      "when input is Chest plain film the target : 14\n",
      "when input is Chest plain film view the target : 27\n",
      "when input is Chest plain film view showed the target : 2\n",
      "when input is Chest plain film view showed: the target : 0\n",
      "when input is Chest plain film view showed:\n",
      " the target : 9\n",
      "when input is Chest plain film view showed:\n",
      "Impression the target : 2\n",
      "when input is Bilateral the target : 112\n",
      "when input is Bilateral hilar the target : 103\n",
      "when input is Bilateral hilar enlargement the target : 1\n",
      "when input is Bilateral hilar enlargement. the target : 0\n",
      "when input is Bilateral hilar enlargement.\n",
      " the target : 24\n",
      "when input is Bilateral hilar enlargement.\n",
      "Normal the target : 12\n",
      "when input is Bilateral hilar enlargement.\n",
      "Normal heart the target : 16\n",
      "when input is Bilateral hilar enlargement.\n",
      "Normal heart size the target : 1\n",
      "when input is \n",
      " the target : 73\n",
      "when input is \n",
      "Chest the target : 23\n",
      "when input is \n",
      "Chest plain the target : 19\n",
      "when input is \n",
      "Chest plain film the target : 14\n",
      "when input is \n",
      "Chest plain film view the target : 27\n",
      "when input is \n",
      "Chest plain film view showed the target : 2\n",
      "when input is \n",
      "Chest plain film view showed: the target : 0\n",
      "when input is \n",
      "Chest plain film view showed:\n",
      " the target : 9\n",
      "when input is \n",
      " the target : 47\n",
      "when input is \n",
      "Bilateral the target : 112\n",
      "when input is \n",
      "Bilateral hilar the target : 103\n",
      "when input is \n",
      "Bilateral hilar enlargement the target : 1\n",
      "when input is \n",
      "Bilateral hilar enlargement. the target : 0\n",
      "when input is \n",
      "Bilateral hilar enlargement.\n",
      " the target : 24\n",
      "when input is \n",
      "Bilateral hilar enlargement.\n",
      "Normal the target : 12\n",
      "when input is \n",
      "Bilateral hilar enlargement.\n",
      "Normal heart the target : 16\n",
      "when input is [CLS] the target : 0\n",
      "when input is [CLS]\n",
      " the target : 73\n",
      "when input is [CLS]\n",
      "Chest the target : 23\n",
      "when input is [CLS]\n",
      "Chest plain the target : 19\n",
      "when input is [CLS]\n",
      "Chest plain film the target : 14\n",
      "when input is [CLS]\n",
      "Chest plain film view the target : 27\n",
      "when input is [CLS]\n",
      "Chest plain film view showed the target : 2\n",
      "when input is [CLS]\n",
      "Chest plain film view showed: the target : 0\n",
      "when input is  lung the target : 372\n",
      "when input is  lung subsegmental the target : 117\n",
      "when input is  lung subsegmental atelectasis the target : 1\n",
      "when input is  lung subsegmental atelectasis. the target : 0\n",
      "when input is  lung subsegmental atelectasis.\n",
      " the target : 41\n",
      "when input is  lung subsegmental atelectasis.\n",
      "Blunting the target : 17\n",
      "when input is  lung subsegmental atelectasis.\n",
      "Blunting left the target : 31\n",
      "when input is  lung subsegmental atelectasis.\n",
      "Blunting left CP the target : 68\n",
      "when input is \n",
      " the target : 42\n",
      "when input is \n",
      "DJD the target : 4\n",
      "when input is \n",
      "DJD of the target : 11\n",
      "when input is \n",
      "DJD of spine the target : 1\n",
      "when input is \n",
      "DJD of spine. the target : 0\n",
      "when input is \n",
      "DJD of spine.\n",
      " the target : 118\n",
      "when input is \n",
      "DJD of spine.\n",
      "Mild the target : 131\n",
      "when input is \n",
      "DJD of spine.\n",
      "Mild scoliosis the target : 4\n",
      "when input is \n",
      " the target : 47\n",
      "when input is \n",
      "Bilateral the target : 57\n",
      "when input is \n",
      "Bilateral apical the target : 21\n",
      "when input is \n",
      "Bilateral apical pleural the target : 58\n",
      "when input is \n",
      "Bilateral apical pleural thickening the target : 1\n",
      "when input is \n",
      "Bilateral apical pleural thickening. the target : 0\n",
      "when input is \n",
      "Bilateral apical pleural thickening.\n",
      " the target : 128\n",
      "when input is \n",
      "Bilateral apical pleural thickening.\n",
      "Left the target : 30\n",
      "when input is  showed the target : 2\n",
      "when input is  showed: the target : 0\n",
      "when input is  showed:\n",
      " the target : 9\n",
      "when input is  showed:\n",
      "Impression the target : 2\n",
      "when input is  showed:\n",
      "Impression: the target : 0\n",
      "when input is  showed:\n",
      "Impression:\n",
      " the target : 47\n",
      "when input is  showed:\n",
      "Impression:\n",
      "Bilateral the target : 57\n",
      "when input is  showed:\n",
      "Impression:\n",
      "Bilateral apical the target : 21\n",
      "when input is Left the target : 30\n",
      "when input is Left lower the target : 3\n",
      "when input is Left lower lung the target : 372\n",
      "when input is Left lower lung subsegmental the target : 117\n",
      "when input is Left lower lung subsegmental atelectasis the target : 1\n",
      "when input is Left lower lung subsegmental atelectasis. the target : 0\n",
      "when input is Left lower lung subsegmental atelectasis.\n",
      " the target : 41\n",
      "when input is Left lower lung subsegmental atelectasis.\n",
      "Blunting the target : 17\n",
      "when input is . the target : 0\n",
      "when input is .\n",
      " the target : 47\n",
      "when input is .\n",
      "Bilateral the target : 112\n",
      "when input is .\n",
      "Bilateral hilar the target : 103\n",
      "when input is .\n",
      "Bilateral hilar enlargement the target : 1\n",
      "when input is .\n",
      "Bilateral hilar enlargement. the target : 0\n",
      "when input is .\n",
      "Bilateral hilar enlargement.\n",
      " the target : 24\n",
      "when input is .\n",
      "Bilateral hilar enlargement.\n",
      "Normal the target : 12\n",
      "when input is Bilateral the target : 112\n",
      "when input is Bilateral hilar the target : 103\n",
      "when input is Bilateral hilar enlargement the target : 1\n",
      "when input is Bilateral hilar enlargement. the target : 0\n",
      "when input is Bilateral hilar enlargement.\n",
      " the target : 24\n",
      "when input is Bilateral hilar enlargement.\n",
      "Normal the target : 12\n",
      "when input is Bilateral hilar enlargement.\n",
      "Normal heart the target : 16\n",
      "when input is Bilateral hilar enlargement.\n",
      "Normal heart size the target : 1\n",
      "when input is \n",
      " the target : 9\n",
      "when input is \n",
      "Impression the target : 2\n",
      "when input is \n",
      "Impression: the target : 0\n",
      "when input is \n",
      "Impression:\n",
      " the target : 47\n",
      "when input is \n",
      "Impression:\n",
      "Bilateral the target : 57\n",
      "when input is \n",
      "Impression:\n",
      "Bilateral apical the target : 21\n",
      "when input is \n",
      "Impression:\n",
      "Bilateral apical pleural the target : 58\n",
      "when input is \n",
      "Impression:\n",
      "Bilateral apical pleural thickening the target : 1\n",
      "when input is \n",
      " the target : 128\n",
      "when input is \n",
      "Left the target : 30\n",
      "when input is \n",
      "Left lower the target : 3\n",
      "when input is \n",
      "Left lower lung the target : 372\n",
      "when input is \n",
      "Left lower lung subsegmental the target : 117\n",
      "when input is \n",
      "Left lower lung subsegmental atelectasis the target : 1\n",
      "when input is \n",
      "Left lower lung subsegmental atelectasis. the target : 0\n",
      "when input is \n",
      "Left lower lung subsegmental atelectasis.\n",
      " the target : 41\n",
      "when input is . the target : 0\n",
      "when input is .\n",
      " the target : 42\n",
      "when input is .\n",
      "DJD the target : 4\n",
      "when input is .\n",
      "DJD of the target : 11\n",
      "when input is .\n",
      "DJD of spine the target : 1\n",
      "when input is .\n",
      "DJD of spine. the target : 0\n",
      "when input is .\n",
      "DJD of spine.\n",
      " the target : 118\n",
      "when input is .\n",
      "DJD of spine.\n",
      "Mild the target : 131\n"
     ]
    }
   ],
   "source": [
    "# testing batch\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(8):\n",
    "        context = x[b, :t+1]\n",
    "        target = y[b, t]\n",
    "        print(f'when input is {decode(context.tolist())} the target : {(target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_head, n_embd):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.c_attn = nn.Linear(n_embd, n_embd * 3)\n",
    "        self.c_proj = nn.Linear(n_embd, n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # batch_size, Seq_len, embedding dim\n",
    "        B, T, C = x.shape\n",
    "        # print(x.shape)\n",
    "        # after c_attn(x), the shape is B, T, n_embd * 3\n",
    "        a = self.c_attn(x)\n",
    "        q, k, v = a.split(self.n_embd, dim=2)\n",
    "        # start view() & transpose()\n",
    "        # shape after transpose (Batch_size, n_head, Seq_len, n_embd // n_head) \n",
    "        # or (B, n_head, T, C // n_head)\n",
    "        q = q.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(2, 1)\n",
    "        k = k.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(2, 1)\n",
    "        v = v.view(B, T, self.n_head, self.n_embd // self.n_head).transpose(2, 1)\n",
    "        # the formula : softmax(QK^T / sqrt(embd_dim(k)))V\n",
    "        # shape after q @ k : (B, n_head, T, T) \n",
    "        attn = q @ k.transpose(-2, -1) * (1 / math.sqrt(self.n_embd * 3 // self.n_head))\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        # shape after attn @ v : (B, n_head, T, C // n_head)\n",
    "        y = attn @ v\n",
    "        y = y.transpose(2, 1).contiguous().view(B, T, C)\n",
    "        self.out = self.c_proj(y)\n",
    "        return self.out   \n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embd, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, n_embd)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape (B, T, C)\n",
    "        x = x + self.sa(self.ln1(x))        # (B, T, C)\n",
    "        x = x + self.ffwd(self.ln2(x))      # (B, T, C)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, block_size, n_embd, n_head, device, n_layer=8):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = torch.nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = torch.nn.Embedding(block_size, n_embd)\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        B, T = idx.shape\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=self.device)) # (T, C)\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        \n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            \n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T)\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            idx_cond = idx[:, -block_size:] # prevent longer block_size, because we just have pos. embd\n",
    "            logits, loss = self(idx_cond) # now (B, T, C)\n",
    "            logits = logits[:, -1, :] # now get the last step and shape (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(stoi)\n",
    "block_size = 8\n",
    "batch_size = 16\n",
    "n_embd = 64\n",
    "n_head = 8\n",
    "lr = 3e-4\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.5671, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " tensor([[ 0.4061, -2.1083,  1.9879,  ...,  0.4030,  0.9246, -1.4002],\n",
       "         [-0.7751, -1.2046,  1.1527,  ...,  0.0882,  0.2441,  0.1490],\n",
       "         [-0.3635,  0.8363,  2.2423,  ...,  1.6556, -0.2339, -1.9837],\n",
       "         ...,\n",
       "         [ 0.3923,  0.1061,  1.3098,  ..., -1.1390,  0.4697,  0.0408],\n",
       "         [-1.2468,  0.3537,  1.0895,  ...,  0.5701,  1.7140,  0.3968],\n",
       "         [ 0.4524, -0.2578,  0.4114,  ..., -0.3118,  0.0381, -1.3742]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Decoder(vocab_size=vocab_size, block_size=block_size, n_embd=n_embd, n_head=n_head, device='cuda')\n",
    "\n",
    "# test model\n",
    "x, y = CustomBlockSeq2Batch(train_df, block_size, batch_size, device='cuda')\n",
    "m = model.to(device)\n",
    "\n",
    "logits, loss = m(x, y)\n",
    "loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4539265632629395\n",
      "0.9163804650306702\n",
      "0.0919528678059578\n",
      "0.02621680498123169\n",
      "0.0687696784734726\n",
      "0.011287350207567215\n",
      "0.03207331895828247\n",
      "0.012525674887001514\n",
      "0.04374454915523529\n",
      "0.013384126126766205\n",
      "[CLS] Chest infiltrates infiltrates infiltrates infiltrates infiltrates infiltrates infiltrates infiltrates infiltrates infiltrates infiltrates linear infiltratesPulmonary TB infiltrates and plain infiltrates and small infiltrates and tubes\n",
      "Suspect hiatal left lower lung field.\n",
      "Blunting of left costophrenic angle.\n",
      "\n",
      "Enlarged cardiac silhouette.\n",
      "\n",
      "Heterogeneous bone density and partial collapse of T9 and T11 vertebrae.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=lr)\n",
    "\n",
    "for iter in range(10000):\n",
    "    \n",
    "    xb, yb = CustomBlockSeq2Batch(train_df, block_size, batch_size, device='cuda', target_idx=iter)\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iter % 1000 == 0:\n",
    "        print(loss.item())\n",
    "        \n",
    "context = torch.tensor([[stoi['[CLS]']]], dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=60)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] infiltrations medial calcified aortic fixation on infiltration on small calcified aortic artery metastasis.\n",
      " Surgical lower lung patch.\n",
      "Bilateral pleural thickening.\n",
      "Tortuous atherosclerotic aorta.\n",
      "Normal heart size.\n",
      "Atherosclerotic aorta.\n",
      "Old fracture of bilateral ribs.\n",
      "S/P pacemaker subclavian\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor([[stoi['[CLS]']]], dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=50)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
